{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
        }
      }
    }
  },
  "cells": [
    {
      "source": [
        "## Libraries and config"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.2\n",
            "Python 3.7.10\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow==1.15 in /home/oh/.local/lib/python3.7/site-packages (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (3.15.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.20.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /home/oh/.local/lib/python3.7/site-packages (from tensorflow==1.15) (1.36.1)\n",
            "Requirement already satisfied: h5py in /home/oh/.local/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/oh/.local/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/oh/.local/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (47.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/oh/.local/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /home/oh/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.3)\n",
            "Requirement already satisfied: cached-property in /home/oh/.local/lib/python3.7/site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/oh/.local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /home/oh/.local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/oh/.local/lib/python3.7/site-packages (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/oh/.local/lib/python3.7/site-packages (1.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /home/oh/.local/lib/python3.7/site-packages (from pandas) (1.20.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/oh/.local/lib/python3.7/site-packages (from pandas) (2021.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/oh/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/oh/.local/lib/python3.7/site-packages (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sklearn in /usr/lib/python3.7/site-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/lib/python3.7/site-packages (from sklearn) (0.21.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /home/oh/.local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: statsmodels in /home/oh/.local/lib/python3.7/site-packages (0.12.2)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/lib/python3.7/site-packages (from statsmodels) (1.3.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /home/oh/.local/lib/python3.7/site-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21 in /home/oh/.local/lib/python3.7/site-packages (from statsmodels) (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/oh/.local/lib/python3.7/site-packages (from statsmodels) (1.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3.7/site-packages (from pandas>=0.21->statsmodels) (2.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/oh/.local/lib/python3.7/site-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
            "Requirement already satisfied: six in /home/oh/.local/lib/python3.7/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /usr/lib/python3.7/site-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /home/oh/.local/lib/python3.7/site-packages (from matplotlib) (1.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/oh/.local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six in /home/oh/.local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /home/oh/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (47.1.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras==2.3.1 in /home/oh/.local/lib/python3.7/site-packages (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/oh/.local/lib/python3.7/site-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /home/oh/.local/lib/python3.7/site-packages (from keras==2.3.1) (5.4.1)\n",
            "Requirement already satisfied: h5py in /home/oh/.local/lib/python3.7/site-packages (from keras==2.3.1) (3.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/oh/.local/lib/python3.7/site-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /home/oh/.local/lib/python3.7/site-packages (from keras==2.3.1) (1.20.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /home/oh/.local/lib/python3.7/site-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/lib/python3.7/site-packages (from keras==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: cached-property in /home/oh/.local/lib/python3.7/site-packages (from h5py->keras==2.3.1) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!python3.7 --version\n",
        "!python3.7 -m pip install tensorflow==1.15\n",
        "!python3.7 -m pip install numpy\n",
        "!python3.7 -m pip install pandas\n",
        "!python3.7 -m pip install numpy\n",
        "!python3.7 -m pip install sklearn\n",
        "!python3.7 -m pip install statsmodels\n",
        "!python3.7 -m pip install matplotlib\n",
        "!python3.7 -m pip install keras==2.3.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3tKGcLkrmvV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import json\n",
        "\n",
        "import pandas as pd # data manipulation library\n",
        "import numpy as np # math library\n",
        "\n",
        "import sklearn.metrics as sklm # metrics\n",
        "import statsmodels as sm # statistical models\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam, Adagrad\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "import tensorflow as tf # machine learning library\n",
        "import os\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "tf.compat.v1.reset_default_graph()\n",
        "tf.compat.v1.random.set_random_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "from keras.layers import SimpleRNN"
      ]
    },
    {
      "source": [
        "## Utils"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_data(flow_interval):\n",
        "    path = \"{0}dataset/dataset_flow_{1}.csv\".format(PATH, flow_interval)\n",
        "    print(PATH)\n",
        "    data = pd.read_csv(path, ';')\n",
        "    \n",
        "    data['Flow'].apply(int)\n",
        "    data['AveSpeed'].apply(float)\n",
        "    data['Density'].apply(float)\n",
        "    data['Sunday'].apply(int)\n",
        "    data['Monday'].apply(int)\n",
        "    data['Tuesday'].apply(int)\n",
        "    data['Wednesday'].apply(int)\n",
        "    data['Thursday'].apply(int)\n",
        "    data['Friday'].apply(int)\n",
        "    data['Saturday'].apply(int)\n",
        "      \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store(obj, path, name):\n",
        "  with open(\"{0}{1}/{2}.json\".format(PATH, path, name), 'w') as json_file:\n",
        "    json.dump(obj, json_file, sort_keys=True, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(data, useB, n_steps, n_future):\n",
        "  \"\"\" Generate Dataset\n",
        "  \n",
        "  Generate a dataset provided a sequence. Reshape the sequence in rolling intervals from [samples, timesteps] into \n",
        "  [samples, timesteps, features] and split the sequence. The split the sequence in rolling intervals with a corresponding value \n",
        "  like the example bellow.\n",
        "\n",
        "  Ex: split_sequence([1, 2, 3, 4, 5], 3) #([[1, 2, 3], [2, 3, 4]], [4, 5])\n",
        "  \n",
        "  Arguments:\n",
        "    raw_seq: the sequence to reshape.\n",
        "    useB: if the dataset is more complex or not.\n",
        "    n_steps: size of the rolling interval\n",
        "    n_future: the distance to the interval the value should be.  \n",
        "  \"\"\"\n",
        "\n",
        "  sequence = np.array(data if useB else data['Flow'])\n",
        "\n",
        "  n = len(sequence)\n",
        "  X, Y = list(), list()\n",
        "\n",
        "  for i in range(n):\n",
        "    j = i + n_steps\n",
        "    k = j + n_future\n",
        "\n",
        "    if k >= n:\n",
        "      break\n",
        "\n",
        "    seq_x, seq_y = sequence[i:j], sequence[k]\n",
        "    X.append(seq_x)\t\n",
        "    Y.append(seq_y[0] if useB else seq_y)\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\t\n",
        "  \n",
        "  if not useB:\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate (expected, observed, times, name):\n",
        "  \"\"\" Evaluate Sessions\n",
        "  \n",
        "  Evaluate models by RMSE, NRMSE, MAE, HR, PRE. It will store the \n",
        "  results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each \n",
        "      train&test session.\n",
        "    observed: an array of observed instances of each \n",
        "      train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "    name: the name of the model\n",
        "  \"\"\"\n",
        "  n = len(expected)\n",
        "  flatten = lambda l : [i for sl in l for i in sl]\n",
        "  \n",
        "  # Make the arrays serializable\n",
        "  expected = list(map(list, expected))\n",
        "  observed = list(map(list, observed))\n",
        "  \n",
        "  for i in range(n):\n",
        "    expected[i] = list(map(float, expected[i]))\n",
        "    observed[i] = list(map(float, observed[i]))\n",
        "  \n",
        "  raw = evaluate_raw(expected, observed, times)\n",
        "  \n",
        "  #n_buckets = len(raw['PRE'])\n",
        "  #_pre = [[pre[i] for pre in raw['PRE']] for i in range(n_buckets)]\n",
        "  \n",
        "  eva = {\n",
        "    'TIME': int(sum(times)),\n",
        "    'RMSE': float(np.mean(raw['RMSE'])),\n",
        "    # 'NRMSE': float(np.mean(raw['NRMSE'])),\n",
        "    'MAE': float(np.mean(raw['MAE'])),\n",
        "    'HR': float(np.mean(raw['HR'])),\n",
        "    #'PRE': [float(np.mean(p)) for p in _pre],\n",
        "    'has_negative': (min(flatten(observed)) < 0),\n",
        "    'raw': raw\n",
        "  }\n",
        "  \n",
        "  print(\"\\n{0} Final Result:\".format(name))\n",
        "  print(\"\\tTotal Time: {0}s\".format(eva['TIME']))\n",
        "  print(\"\\tRMSE: {0}\".format(eva['RMSE']))\n",
        "  # print(\"\\tNRMSE: {0}\".format(eva['NRMSE']))\n",
        "  print(\"\\tMAE: {0}\".format(eva['MAE']))\n",
        "  print(\"\\tHit Ratio: {0}%\".format(eva['HR'] * 100))\n",
        "  #print(\"\\tPrecision: {0}\".format(eva['PRE']))\n",
        "    \n",
        "  return eva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_raw (expected, observed, times):\n",
        "  \"\"\" Evaluate Raw Sessions \n",
        "  \n",
        "  Evaluate each of the train&test sessions by RMSE, NRMSE, MAE, HR, PRE. \n",
        "  It will store the results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each train&test session.\n",
        "    observed: an array of observed instances of each train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "  \"\"\"\n",
        "  \n",
        "  n = len(expected)\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [0 if np.isnan(o) else o for o in observed[i]]\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [max(o, 0) for o in observed[i]]\n",
        "  \n",
        "  raw = {\n",
        "    'expected': expected,\n",
        "    'observed': observed,\n",
        "    'TIME': times,\n",
        "    'RMSE': [0] * n,\n",
        "    # 'NRMSE': [0] * n,\n",
        "    'MAE': [0] * n,\n",
        "    'HR': [0] * n,\n",
        "    #'PRE': [0] * n,\n",
        "  }\n",
        "  \n",
        "  for i in range(n):\n",
        "    Y = expected[i]\n",
        "    Y_hat = observed[i]\n",
        "    time = times[i]\n",
        "\n",
        "    raw['MAE'][i] = sklm.mean_absolute_error(Y, Y_hat)\n",
        "    raw['RMSE'][i] = np.sqrt(sklm.mean_squared_error(Y, Y_hat))\n",
        "    # raw['NRMSE'][i] = raw['RMSE'][i] / np.std(Y)\n",
        "    raw['HR'][i] = evaluate_precision_hit_ratio(Y, Y_hat)\n",
        "    #raw['PRE'][i] = evaluate_precision_bucket(Y, Y_hat)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      print(\"({0}/{1}) Test Size: {2}, Time: {3}s\".format(i+1, n, len(Y), time))\n",
        "      print(\"\\tRMSE: {0}\".format(raw['RMSE'][i]))\n",
        "      # print(\"\\tNRMSE: {0}\".format(raw['NRMSE'][i]))\n",
        "      print(\"\\tMAE: {0}\".format(raw['MAE'][i]))\n",
        "      print(\"\\tHit Ratio: {0}%\".format(raw['HR'][i] * 100))\n",
        "\n",
        "  return raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_precision_hit_ratio (Y, Y_hat):\n",
        "  \"\"\" Trend Prediction Ratio Calculation\n",
        "  \n",
        "  Calculates the ratio of up/down prediction.\n",
        "  \n",
        "  Arguments:\n",
        "    Y: the expected dataset.\n",
        "    Y_hat: the observed dataset.\n",
        "  \"\"\"\n",
        "  \n",
        "  cnt = 0\n",
        "  \n",
        "  for i in range(len(Y)):\n",
        "    if i < N_FUTURE:\n",
        "      continue\n",
        "      \n",
        "    exp = Y[i] - Y[i - N_FUTURE]\n",
        "    obs = Y_hat[i] - Y[i - N_FUTURE]\n",
        "    \n",
        "    if exp * obs > 0:\n",
        "      cnt += 1\n",
        "    \n",
        "  return cnt / len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_prediction (Y, Y_hat, title):\n",
        "  \"\"\" Plot Prediction\n",
        "  \n",
        "  Plot the prediction (Flow x Time) of what was expected and what\n",
        "  was predicted.\n",
        "  \"\"\"\n",
        "\n",
        "  name = f\"{title}\"\n",
        "  path = f\"plots/prediction/{name}\"\n",
        "  \n",
        "  plt.plot(Y)\n",
        "  plt.plot(Y_hat)\n",
        "  plt.title(f\"Predição do Modelo {title}\")\n",
        "  plt.ylabel('Fluxo')\n",
        "  plt.xlabel('Tempo')\n",
        "  plt.legend(['esperado', 'observado'], loc='upper left')\n",
        "  plt.rcdefaults()\n",
        "  plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "  plt.close('all')"
      ]
    },
    {
      "source": [
        "## Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "SEEABLE_PAST = 480 # in minutes\n",
        "PREDICT_IN_FUTURE = 60 # in minutes\n",
        "FLOW_INTERVAL = 150 # the interval size for each flow\n",
        "N_SPLITS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Derivated Model Parameters\n",
        "N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL # the number of flows to see in the past\n",
        "N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL # how much in the future we want to predict (0 = predict the flow on the next FLOW_INTERVAL minutes)\n",
        "DAY_SIZE = (24 * 60 * 60) // FLOW_INTERVAL  \n",
        "WEEK_SIZE = (7 * 24 * 60 * 60) // FLOW_INTERVAL\n",
        "VERBOSITY = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "#data.loc[48871]\n",
        "def split_dataset():\n",
        "    return 44850"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rnn (data, useB): \n",
        "  global result_data\n",
        "  \n",
        "  name = \"RNN B\" if useB else \"RNN A\"\n",
        "  \n",
        "  X, Y = generate_dataset(data, useB, N_STEPS, N_FUTURE)\n",
        "  \n",
        "  model = Sequential()\t\t\n",
        "\n",
        "  model.add(SimpleRNN(50, activation='relu', input_shape=(X.shape[1], X.shape[2])))\t\t\n",
        "  model.add(Dense(1))\t\t\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mse', metrics = [\"accuracy\"])\n",
        "  \n",
        "  pointer = split_dataset()\n",
        "    \n",
        "  h = model.fit(X[0:pointer], Y[0:pointer], validation_split=0.2, batch_size=64, epochs=15, verbose=2)\n",
        "\n",
        "  return h, [X[(pointer + 1):], Y[(pointer + 1):]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n",
            "Train on 35880 samples, validate on 8970 samples\n",
            "Epoch 1/15\n",
            " - 17s - loss: 34.0857 - accuracy: 0.0779 - val_loss: 48.1039 - val_accuracy: 0.1577\n",
            "Epoch 2/15\n",
            " - 17s - loss: 26.6415 - accuracy: 0.0858 - val_loss: 40.6710 - val_accuracy: 0.0520\n",
            "Epoch 3/15\n",
            " - 17s - loss: 25.7444 - accuracy: 0.0694 - val_loss: 38.9430 - val_accuracy: 0.0569\n",
            "Epoch 4/15\n",
            " - 18s - loss: 24.7882 - accuracy: 0.0694 - val_loss: 38.1233 - val_accuracy: 0.0567\n",
            "Epoch 5/15\n",
            " - 17s - loss: 24.2761 - accuracy: 0.0715 - val_loss: 37.2834 - val_accuracy: 0.0612\n",
            "Epoch 6/15\n",
            " - 17s - loss: 23.8253 - accuracy: 0.0737 - val_loss: 35.1464 - val_accuracy: 0.0609\n",
            "Epoch 7/15\n",
            " - 17s - loss: 23.4098 - accuracy: 0.0753 - val_loss: 36.2915 - val_accuracy: 0.0588\n",
            "Epoch 8/15\n",
            " - 17s - loss: 22.7051 - accuracy: 0.0794 - val_loss: 36.6827 - val_accuracy: 0.0506\n",
            "Epoch 9/15\n",
            " - 17s - loss: 23.3199 - accuracy: 0.0772 - val_loss: 34.6154 - val_accuracy: 0.0598\n",
            "Epoch 10/15\n",
            " - 17s - loss: 22.8549 - accuracy: 0.0774 - val_loss: 34.9552 - val_accuracy: 0.0612\n",
            "Epoch 11/15\n",
            " - 17s - loss: 22.3510 - accuracy: 0.0790 - val_loss: 36.0165 - val_accuracy: 0.0609\n",
            "Epoch 12/15\n",
            " - 17s - loss: 21.9785 - accuracy: 0.0797 - val_loss: 34.7750 - val_accuracy: 0.0709\n",
            "Epoch 13/15\n",
            " - 17s - loss: 22.1756 - accuracy: 0.0800 - val_loss: 35.3063 - val_accuracy: 0.0612\n",
            "Epoch 14/15\n",
            " - 17s - loss: 22.5441 - accuracy: 0.0789 - val_loss: 35.9595 - val_accuracy: 0.0579\n",
            "Epoch 15/15\n",
            " - 18s - loss: 21.8097 - accuracy: 0.0788 - val_loss: 35.3974 - val_accuracy: 0.0590\n"
          ]
        }
      ],
      "source": [
        "global result_data\n",
        "  \n",
        "result_data = {\n",
        "    'results': {},\n",
        "    'meta': {\n",
        "      'SEEABLE_PAST': SEEABLE_PAST,\n",
        "      'PREDICT_IN_FUTURE': PREDICT_IN_FUTURE,\n",
        "      'FLOW_INTERVAL': FLOW_INTERVAL,\n",
        "      'N_SPLITS': N_SPLITS,\n",
        "    }\n",
        "}\n",
        "\n",
        "data = retrieve_data(FLOW_INTERVAL)\n",
        "\n",
        "history, validation = rnn(data, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction = history.model.predict(validation[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_prediction(validation[1], prediction, \"RNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1/1) Test Size: 7925, Time: 0s\n\tRMSE: 5.86646469752409\n\tMAE: 4.437623969824156\n\tHit Ratio: 53.23659305993691%\n\nRNN Final Result:\n\tTotal Time: 0s\n\tRMSE: 5.86646469752409\n\tMAE: 4.437623969824156\n\tHit Ratio: 53.23659305993691%\n"
          ]
        }
      ],
      "source": [
        "ev = evaluate([validation[1]], [prediction], [0], \"RNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "store(ev, 'results', 'RNN')"
      ]
    }
  ]
}