{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "source": [
        "## Libraries"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3tKGcLkrmvV"
      },
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install pandas\n",
        "!pip3 install numpy\n",
        "!pip3 install sklearn\n",
        "!pip3 install statsmodels\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import json\n",
        "\n",
        "import pandas as pd # data manipulation library\n",
        "import numpy as np # math library\n",
        "\n",
        "import sklearn.metrics as sklm # metrics\n",
        "import statsmodels as sm # statistical models\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/oh/.local/lib/python3.9/site-packages (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/oh/.local/lib/python3.9/site-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /home/oh/.local/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /home/oh/.local/lib/python3.9/site-packages (from pandas) (1.20.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/oh/.local/lib/python3.9/site-packages (from pandas) (2021.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/oh/.local/lib/python3.9/site-packages (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sklearn in /home/oh/.local/lib/python3.9/site-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /home/oh/.local/lib/python3.9/site-packages (from sklearn) (0.24.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/oh/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/oh/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/oh/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /home/oh/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/oh/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: statsmodels in /home/oh/.local/lib/python3.9/site-packages (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/oh/.local/lib/python3.9/site-packages (from statsmodels) (1.20.1)\n",
            "Requirement already satisfied: pandas>=0.21 in /home/oh/.local/lib/python3.9/site-packages (from statsmodels) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1 in /home/oh/.local/lib/python3.9/site-packages (from statsmodels) (1.6.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /home/oh/.local/lib/python3.9/site-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/oh/.local/lib/python3.9/site-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/oh/.local/lib/python3.9/site-packages (from statsmodels) (1.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /home/oh/.local/lib/python3.9/site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/oh/.local/lib/python3.9/site-packages (from statsmodels) (1.20.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3.9/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3.9/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/oh/.local/lib/python3.9/site-packages (from statsmodels) (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /home/oh/.local/lib/python3.9/site-packages (3.3.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3.9/site-packages (from matplotlib) (8.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/oh/.local/lib/python3.9/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/oh/.local/lib/python3.9/site-packages (from matplotlib) (1.20.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/oh/.local/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /home/oh/.local/lib/python3.9/site-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3.9/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3.9/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Utils"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WalkingForwardTimeSeriesSplit():\n",
        "  def __init__(self, n_splits):\n",
        "    self.n_splits = n_splits\n",
        "  \n",
        "  def get_n_splits(self, X, y, groups):\n",
        "    return self.n_splits\n",
        "  \n",
        "  def split(self, X, y=None, groups=None):\n",
        "    n_samples = len(X)\n",
        "    k_fold_size = n_samples // self.n_splits\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    margin = 0\n",
        "    for i in range(self.n_splits):\n",
        "      start = i * k_fold_size\n",
        "      stop = start + k_fold_size\n",
        "      mid = int(0.8 * (stop - start)) + start\n",
        "      yield indices[start: mid], indices[mid + margin: stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_cv_results(cv_results):\n",
        "  res = copy.deepcopy(cv_results)\n",
        "  for key in res:\n",
        "    if type(res[key]) != list: \n",
        "      res[key] = res[key].tolist()\n",
        "\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_data(flow_interval):\n",
        "    path = \"{0}dataset/dataset_flow_{1}.csv\".format(PATH, flow_interval)\n",
        "    print(PATH)\n",
        "    data = pd.read_csv(path, ';')\n",
        "    \n",
        "    data['Flow'].apply(int)\n",
        "    data['AveSpeed'].apply(float)\n",
        "    data['Density'].apply(float)\n",
        "    data['Sunday'].apply(int)\n",
        "    data['Monday'].apply(int)\n",
        "    data['Tuesday'].apply(int)\n",
        "    data['Wednesday'].apply(int)\n",
        "    data['Thursday'].apply(int)\n",
        "    data['Friday'].apply(int)\n",
        "    data['Saturday'].apply(int)\n",
        "      \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_json (obj):\n",
        "  print(json.dumps(obj, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store(obj, path, name):\n",
        "  with open(\"{0}{1}/{2}.json\".format(PATH, path, name), 'w') as json_file:\n",
        "    json.dump(obj, json_file, sort_keys=True, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_results ():\n",
        "  name = int(time.time())\n",
        "  \n",
        "  result_data['meta'] = {\n",
        "    \"SEEABLE_PAST\": SEEABLE_PAST,\n",
        "    \"PREDICT_IN_FUTURE\": PREDICT_IN_FUTURE,\n",
        "    \"FLOW_INTERVAL\": FLOW_INTERVAL,\n",
        "    \"N_SPLITS\": N_SPLITS,\n",
        "  }\n",
        "\n",
        "  store(result_data, \"results\", name)\n",
        "\n",
        "  slim_result_data = copy.deepcopy(result_data)\n",
        "  for model in slim_result_data['results']:\n",
        "      del slim_result_data['results'][model]['raw']\n",
        "\n",
        "  store(slim_result_data, \"results\", \"{0}_slim\".format(name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_comparisons (title):\n",
        "  name = str(int(time.time()))\n",
        "  \n",
        "  j = copy.deepcopy(comparison_data)\n",
        "\n",
        "  store(j, \"results/comparison\", \"{0}_{1}\".format(title, name))\n",
        "    \n",
        "  for i in range(len(j)):\n",
        "    for model in j[i]['results']:\n",
        "      del j[i]['results'][model]['raw']\n",
        "\n",
        "  store(j, \"results/comparison\", \"{0}_{1}_slim\".format(title, name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(data, useB, n_steps, n_future):\n",
        "  \"\"\" Generate Dataset\n",
        "  \n",
        "  Generate a dataset provided a sequence. Reshape the sequence in rolling intervals from [samples, timesteps] into \n",
        "  [samples, timesteps, features] and split the sequence. The split the sequence in rolling intervals with a corresponding value \n",
        "  like the example bellow.\n",
        "\n",
        "  Ex: split_sequence([1, 2, 3, 4, 5], 3) #([[1, 2, 3], [2, 3, 4]], [4, 5])\n",
        "  \n",
        "  Arguments:\n",
        "    raw_seq: the sequence to reshape.\n",
        "    useB: if the dataset is more complex or not.\n",
        "    n_steps: size of the rolling interval\n",
        "    n_future: the distance to the interval the value should be.  \n",
        "  \"\"\"\n",
        "\n",
        "  sequence = np.array(data if useB else data['Flow'])\n",
        "\n",
        "  n = len(sequence)\n",
        "  X, Y = list(), list()\n",
        "\n",
        "  for i in range(n):\n",
        "    j = i + n_steps\n",
        "    k = j + n_future\n",
        "\n",
        "    if k >= n:\n",
        "      break\n",
        "\n",
        "    seq_x, seq_y = sequence[i:j], sequence[k]\n",
        "    X.append(seq_x)\t\n",
        "    Y.append(seq_y[0] if useB else seq_y)\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\t\n",
        "  \n",
        "  if not useB:\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate (expected, observed, times, name):\n",
        "  \"\"\" Evaluate Sessions\n",
        "  \n",
        "  Evaluate models by RMSE, NRMSE, MAE, HR, PRE. It will store the \n",
        "  results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each \n",
        "      train&test session.\n",
        "    observed: an array of observed instances of each \n",
        "      train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "    name: the name of the model\n",
        "  \"\"\"\n",
        "  n = len(expected)\n",
        "  flatten = lambda l : [i for sl in l for i in sl]\n",
        "  \n",
        "  # Make the arrays serializable\n",
        "  expected = list(map(list, expected))\n",
        "  observed = list(map(list, observed))\n",
        "  \n",
        "  for i in range(n):\n",
        "    expected[i] = list(map(float, expected[i]))\n",
        "    observed[i] = list(map(float, observed[i]))\n",
        "  \n",
        "  raw = evaluate_raw(expected, observed, times)\n",
        "  \n",
        "  #n_buckets = len(raw['PRE'])\n",
        "  #_pre = [[pre[i] for pre in raw['PRE']] for i in range(n_buckets)]\n",
        "  \n",
        "  eva = {\n",
        "    'TIME': int(sum(times)),\n",
        "    'RMSE': float(np.mean(raw['RMSE'])),\n",
        "    # 'NRMSE': float(np.mean(raw['NRMSE'])),\n",
        "    'MAE': float(np.mean(raw['MAE'])),\n",
        "    'HR': float(np.mean(raw['HR'])),\n",
        "    #'PRE': [float(np.mean(p)) for p in _pre],\n",
        "    'has_negative': (min(flatten(observed)) < 0),\n",
        "    'raw': raw\n",
        "  }\n",
        "  \n",
        "  print(\"\\n{0} Final Result:\".format(name))\n",
        "  print(\"\\tTotal Time: {0}s\".format(eva['TIME']))\n",
        "  print(\"\\tRMSE: {0}\".format(eva['RMSE']))\n",
        "  # print(\"\\tNRMSE: {0}\".format(eva['NRMSE']))\n",
        "  print(\"\\tMAE: {0}\".format(eva['MAE']))\n",
        "  print(\"\\tHit Ratio: {0}%\".format(eva['HR'] * 100))\n",
        "  #print(\"\\tPrecision: {0}\".format(eva['PRE']))\n",
        "    \n",
        "  return eva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_raw (expected, observed, times):\n",
        "  \"\"\" Evaluate Raw Sessions \n",
        "  \n",
        "  Evaluate each of the train&test sessions by RMSE, NRMSE, MAE, HR, PRE. \n",
        "  It will store the results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each train&test session.\n",
        "    observed: an array of observed instances of each train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "  \"\"\"\n",
        "  \n",
        "  n = len(expected)\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [0 if np.isnan(o) else o for o in observed[i]]\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [max(o, 0) for o in observed[i]]\n",
        "  \n",
        "  raw = {\n",
        "    'expected': expected,\n",
        "    'observed': observed,\n",
        "    'TIME': times,\n",
        "    'RMSE': [0] * n,\n",
        "    # 'NRMSE': [0] * n,\n",
        "    'MAE': [0] * n,\n",
        "    'HR': [0] * n,\n",
        "    #'PRE': [0] * n,\n",
        "  }\n",
        "  \n",
        "  for i in range(n):\n",
        "    Y = expected[i]\n",
        "    Y_hat = observed[i]\n",
        "    time = times[i]\n",
        "\n",
        "    raw['MAE'][i] = sklm.mean_absolute_error(Y, Y_hat)\n",
        "    raw['RMSE'][i] = np.sqrt(sklm.mean_squared_error(Y, Y_hat))\n",
        "    # raw['NRMSE'][i] = raw['RMSE'][i] / np.std(Y)\n",
        "    raw['HR'][i] = evaluate_precision_hit_ratio(Y, Y_hat)\n",
        "    #raw['PRE'][i] = evaluate_precision_bucket(Y, Y_hat)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      print(\"({0}/{1}) Test Size: {2}, Time: {3}s\".format(i+1, n, len(Y), time))\n",
        "      print(\"\\tRMSE: {0}\".format(raw['RMSE'][i]))\n",
        "      # print(\"\\tNRMSE: {0}\".format(raw['NRMSE'][i]))\n",
        "      print(\"\\tMAE: {0}\".format(raw['MAE'][i]))\n",
        "      print(\"\\tHit Ratio: {0}%\".format(raw['HR'][i] * 100))\n",
        "\n",
        "  return raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_precision_hit_ratio (Y, Y_hat):\n",
        "  \"\"\" Trend Prediction Ratio Calculation\n",
        "  \n",
        "  Calculates the ratio of up/down prediction.\n",
        "  \n",
        "  Arguments:\n",
        "    Y: the expected dataset.\n",
        "    Y_hat: the observed dataset.\n",
        "  \"\"\"\n",
        "  \n",
        "  cnt = 0\n",
        "  \n",
        "  for i in range(len(Y)):\n",
        "    if i < N_FUTURE:\n",
        "      continue\n",
        "      \n",
        "    exp = Y[i] - Y[i - N_FUTURE]\n",
        "    obs = Y_hat[i] - Y[i - N_FUTURE]\n",
        "    \n",
        "    if exp * obs > 0:\n",
        "      cnt += 1\n",
        "    \n",
        "  return cnt / len(Y)"
      ]
    },
    {
      "source": [
        "## Testing"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "SEEABLE_PAST = 480 # in minutes\n",
        "PREDICT_IN_FUTURE = 60 # in minutes\n",
        "FLOW_INTERVAL = 150 # the interval size for each flow\n",
        "N_SPLITS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Derivated Model Parameters\n",
        "N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL # the number of flows to see in the past\n",
        "N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL # how much in the future we want to predict (0 = predict the flow on the next FLOW_INTERVAL minutes)\n",
        "DAY_SIZE = (24 * 60 * 60) // FLOW_INTERVAL  \n",
        "WEEK_SIZE = (7 * 24 * 60 * 60) // FLOW_INTERVAL\n",
        "VERBOSITY = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naive (X, Y):\n",
        "  global result_data\n",
        "\n",
        "  X = X.reshape(X.shape[0], X.shape[1])\n",
        "\n",
        "  name = \"Naive\"\n",
        "  cv = WalkingForwardTimeSeriesSplit(n_splits=N_SPLITS)\n",
        "  expected, observed, times = [], [], []\n",
        "\n",
        "  for train_index, test_index in cv.split(X):\n",
        "    X_test = X[test_index]\n",
        "    Y_test = Y[test_index]\n",
        "  \n",
        "    start_time = time.time()\n",
        "    Y_hat = [x[-1] for x in X_test]\n",
        "    end_time = time.time()\n",
        "    \n",
        "    expected.append(Y_test)\n",
        "    observed.append(Y_hat)\n",
        "    times.append(end_time - start_time)\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  store(result_data['results'][name], \"results/grid\", \"{0}_{1}\".format(name, PREDICT_IN_FUTURE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n",
            "(1/8) Test Size: 1320, Time: 0.00025582313537597656s\n",
            "\tRMSE: 7.498484695408314\n",
            "\tMAE: 5.321212121212121\n",
            "\tHit Ratio: 45.151515151515156%\n",
            "(2/8) Test Size: 1320, Time: 0.0002472400665283203s\n",
            "\tRMSE: 6.569730864834848\n",
            "\tMAE: 4.526515151515151\n",
            "\tHit Ratio: 38.56060606060606%\n",
            "(3/8) Test Size: 1320, Time: 0.0002639293670654297s\n",
            "\tRMSE: 7.721428271081364\n",
            "\tMAE: 5.721969696969697\n",
            "\tHit Ratio: 47.34848484848485%\n",
            "(4/8) Test Size: 1320, Time: 0.00025010108947753906s\n",
            "\tRMSE: 7.694055162817905\n",
            "\tMAE: 5.045454545454546\n",
            "\tHit Ratio: 38.25757575757576%\n",
            "(5/8) Test Size: 1320, Time: 0.0002491474151611328s\n",
            "\tRMSE: 6.893288347546782\n",
            "\tMAE: 5.009848484848485\n",
            "\tHit Ratio: 42.12121212121212%\n",
            "(6/8) Test Size: 1320, Time: 0.00024962425231933594s\n",
            "\tRMSE: 8.889004102788677\n",
            "\tMAE: 6.338636363636364\n",
            "\tHit Ratio: 44.621212121212125%\n",
            "(7/8) Test Size: 1320, Time: 0.0002484321594238281s\n",
            "\tRMSE: 9.38954931632165\n",
            "\tMAE: 6.775757575757575\n",
            "\tHit Ratio: 41.66666666666667%\n",
            "(8/8) Test Size: 1320, Time: 0.0002512931823730469s\n",
            "\tRMSE: 8.251997003480705\n",
            "\tMAE: 6.112121212121212\n",
            "\tHit Ratio: 43.484848484848484%\n",
            "\n",
            "Naive Final Result:\n",
            "\tTotal Time: 0s\n",
            "\tRMSE: 7.86344222053503\n",
            "\tMAE: 5.606439393939394\n",
            "\tHit Ratio: 42.65151515151515%\n"
          ]
        }
      ],
      "source": [
        "global result_data\n",
        "  \n",
        "result_data = {\n",
        "    'results': {},\n",
        "    'meta': {\n",
        "      'SEEABLE_PAST': SEEABLE_PAST,\n",
        "      'PREDICT_IN_FUTURE': PREDICT_IN_FUTURE,\n",
        "      'FLOW_INTERVAL': FLOW_INTERVAL,\n",
        "      'N_SPLITS': N_SPLITS,\n",
        "    }\n",
        "}\n",
        "\n",
        "data = retrieve_data(FLOW_INTERVAL)\n",
        "X_a, Y_a = generate_dataset(data, False, N_STEPS, N_FUTURE)\n",
        "naive(X_a, Y_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_prediction (Y, Y_hat, title):\n",
        "  \"\"\" Plot Prediction\n",
        "  \n",
        "  Plot the prediction (Flow x Time) of what was expected and what\n",
        "  was predicted.\n",
        "  \"\"\"\n",
        "\n",
        "  for i in range(len(Y)):\n",
        "    name = f\"{title} ({str(i+1).zfill(2)} of {len(Y)})\"\n",
        "    path = f\"plots/prediction/{name}\"\n",
        "    \n",
        "    plt.plot(Y[i])\n",
        "    plt.plot(Y_hat[i])\n",
        "    plt.title(f\"Predição do Modelo {title}\")\n",
        "    plt.ylabel('Fluxo')\n",
        "    plt.xlabel('Tempo')\n",
        "    plt.legend(['esperado', 'observado'], loc='upper left')\n",
        "    plt.rcdefaults()\n",
        "\n",
        "    plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "    # plt.savefig(path + \".pdf\")\n",
        "\n",
        "    plt.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [],
      "source": [
        "expected = result_data['results']['Naive']['raw']['expected']\n",
        "observed = result_data['results']['Naive']['raw']['observed']\n",
        "\n",
        "plot_prediction(expected, observed, \"Naive\")"
      ]
    }
  ]
}